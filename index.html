
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<style type="text/css">
* {
  margin: 5 px;
  padding: 0;
}
html {
  overflow-y:scroll; /*keep scrollbar position present in FF at all times*/
  height: 100%;
  background-color: ;/* #white;*/
  background-image: ; /* url("fib.jpg") #ffc38b;*/
}
a {
  color: #240FDF;
}
a:visited {
  color: #240FDF;
}
a:hover {
  color: #ECCF11;
}
p {
  font-family: "Trebuchet MS", Verdana, Helvetica, sans-serif;
}
blockquote {
    display: block;
    margin-top: 1em;
    margin-bottom: 1em;
    margin-left: 80px;
    margin-right: 80px;
}
table {
    border-style: hidden;
}
li{
  margin: 10px 0;
}
name {
    font-family:  "PT Serif","Georgia","Helvetica Neue",Arial,sans-serif; 
    font-size: 47px;
    font-weight: bold;
}
heading {
    font-family:  "Trebuchet MS", Verdana, Helvetica, sans-serif;
    font-size: 21px;
    font-weight: bold;
}
papertitle {
    font-family:  "Trebuchet MS", Verdana, Helvetica, sans-serif;
    font-size: 18px;
    font-weight: bold;
    }
#friendly_1 {
position:absolute;
left:190px;
top:370px;
width:80px;
}
#text {
position:absolute;
left:19px;
top:270px;
width:80px;
}
#footer {
   width:960px;
   margin:0 auto;
}
#footer p {
   line-height:50px; /* must be same as the amount of padding applied to the bottom of the body so text will center vertically */
   text-align:left; /* align right, left or center */
}
</style>


  <title>Liyi Zhang's Page </title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <p> &nbsp </p>
  <link href='http://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900,100italic,100,300,300italic,400italic,500italic,900italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="70%" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <p>
          <name>Liyi Zhang</name>
        </p>
        <p>
        <img src="zhang-liyi.jpg" width="35%">
        </p>
        <p>
          <a href="Zhang_Liyi_Resume.pdf">Resume</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/liyi-zhang-1b5041139/"> LinkedIn </a> &nbsp/&nbsp
        <a> Email:</a>  lz2574 at columbia dot edu 
        </p>
        </td>
       </tr>
      </table>
  
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
        <td width="100%" valign="middle">
        <p>
        I'm doing undergraduate degree at Columbia University, Columbia College, expecting to graduate in Spring 2021. I'm majoring in Statistics and Applied Mathematics. My research interest lies in the general area of probabilistic Machine Learning. They include approximate Bayesian inference, model checking and combination in the Bayesian workflow, and probabilistic perspectives on Deep Learning.
        </p>
        <p>
        For a framework of research, I use "the Box's Loop", where one follows iterative stages: define a model -> use data to infer hidden quantities -> apply, criticize, and modify the model; and repeat. I work on a diverse range of data, so long as they challenge me to think more deeply about statistical methods. Recently, I have a few works on phylogenetic data.
        </p>
        </td> 
        </tr>
      </table>
 
    <br>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publication</heading>
        </td>
      </tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
    <tr>
      <td width="25%">
        <img src='Images/vcsmc-loglik.png' width="280" height="230">
      </td>
      <td valign="top" width="75%">
        <p>
        <a href="Writings/VCSMC-MLCB.pdf">
            <papertitle>Variational Combinatorial Sequential Monte Carlo in Bayesian Phylogenetic Inference</papertitle>
        </a>
        <br>
          <a href=http://www.cs.columbia.edu/~amoretti/>Antonio K. Moretti</a>,
          <strong>Liyi Zhang</strong>,
          <a href="http://www.cs.columbia.edu/~itsik/">Itsik Pe'er</a>,
        <br>
        <em>Machine Learning in Computational Biology 2020 (MLCB). Oral Presentation. </em><a href="https://github.com/amoretti86/phylo">Code.</a><br>
        </p>
        <p>Bayesian phylogenetic inference is often conducted via local or sequential search algorithms such as random-walk Markov chain Monte Carlo or Combinatorial Sequential Monte Carlo. These methods sample tree topologies and branch lengths, however when MCMC is used to perform evolutionary parameter learning, convergence often requires long runs with inefficient state space exploration. We introduce Variational Combinatorial Sequential Monte Carlo (VCSMC), a novel Variational Inference method that simultaneously performs both parameter inference and model learning. Our method uses sequential search to construct a variational objective defined on the composite space of phylogenetic trees. We show that VCSMC is computationally efficient and explores higher probability spaces when compared with state-of-the-art Hamiltonian Monte Carlo methods. </p>
      </td>
    </tr>
    </table>

    <br>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Projects</heading>
        </td>
      </tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
    <tr>
      <td width="25%">
        <img src='Images/stack-ternary.png' width="280" height="250">
      </td>
      <td valign="top" width="75%">
        <p>
        <papertitle>Model Stacking in Bayesian Phylogenetic Inference</papertitle>
        <br>
        <em>Columbia Statistics - Undergraduate Internship. Work in Progress. </em> <br>
        </p>
        <p>I'm working with Professor Andrew Gelman to develop MCMC method in R and Stan to sample in discrete spaces in phylogenetic models by isolating discrete models and using stacking of predictive distributions for model combination. Here, I'm still in the process of diagnosing MCMC inference and exploring properties of stacking as a method of model averaging.</p>
      </td>
    </tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
    <tr>
      <td width="25%">
        <img src='Images/svrg.png' width="280" height="250">
      </td>
      <td valign="top" width="75%">
        <p>
        <a href="Writings/SVRG_report.pdf">
            <papertitle>Stochastic Variance Reduction for Nonconvex Optimization</papertitle>
        </a>
        <br>
        <em>COMS 4995 Optimization Methods in Machine Learning - In-Class Group Project. </em><a href="https://github.com/ryandgoldenberg1/svrg_project">Code.</a><br>
        </p>
        <p>Stochastic Variance Reduced Gradient (SVRG) is one of the popular method proposed to reduce the variance of gradient in the optimization. In this project, we evaluate its result on nonconvex optimization. We study the method without the convex assumption and try to reproduce previous experiment results to verify their claims. However, we can only partially reproduce their result and the advantage against SGD no longer holds when we use deeper network.</p>
      </td>
    </tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
    <tr>
      <td width="25%">
        <img src='Images/topics.png' width="280" height="250">
      </td>
      <td valign="top" width="75%">
        <p>
        <a href="Writings/gibbs_sampler.pdf">
            <papertitle>Text Clustering with the Gibbs Sampler</papertitle>
        </a><br>
        <em>STCS 6701 Foundations of Graphical Models - In-Class Individual Assignment. </em><a href="https://github.com/zhang-liyi/gibbs-sampler/blob/master/gibbs_sampler.R">Code.</a><br>
        </p>
        <p>I did a from-scratch implementation of a Gibbs Sampler and explored its properties. It clusters text data using 2000+ articles from the AP dataset with the Poisson mixture model, generating meaningful topics using TFIDF-inspired term-score. </p>
      </td>
    </tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
    <tr>
      <td width="25%">
        <img src='Images/pso.png' width="280" height="250">
      </td>
      <td valign="top" width="75%">
        <p>
        <a href="Writings/PSO.pdf">
            <papertitle>Effectiveness and Robustness of Networks in Particle Swarm Optimization</papertitle>
        </a>
        <br>
        <em>Complex Resilient Intelligent Systems Lab - Undergraduate Research Project </em>  <br>
        </p>
        <p>Particle swarm optimization (PSO) is a nature-inspired computational method, in which a swarm of particles solves a problem, and each particle improves its individual solution through interaction with its neighbors. PSO has been successfully applied in a range of practical problems aiming at searching for the global optimum. However, PSO often suffers from premature convergence to local optima. We seek to investigate how network topologies influence its performance. Furthermore, we explore the robustness of these network topologies by incorporating the removal rate of the particles: with a given possibility, particles are getting removed from the game after a fixed number of iterations. In that case, even if some topologies have the same connectivity, they yield different performances. We show the optimization game on several different functions and discuss these factorsâ€™ influence on the efficacy and potential of PSO, as well as ideas for further exploration in this area of study.</p>
      </td>
    </tr>
    </table>


    <p> &nbsp </p>
    <p> &nbsp </p>  
  </body>
</html>
