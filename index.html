
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<style type="text/css">
* {
  margin: 5 px;
  padding: 0;
}
html {
  overflow-y:scroll; /*keep scrollbar position present in FF at all times*/
  height: 100%;
  background-color: ;/* #white;*/
  background-image: ; /* url("fib.jpg") #ffc38b;*/
}
a {
  color: #638;
}
a:visited {
  color: #638;
}
p {
  font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
}
blockquote {
    display: block;
    margin-top: 1em;
    margin-bottom: 1em;
    margin-left: 80px;
    margin-right: 80px;
}
table {
    border-style: hidden;
}
li{
  margin: 10px 0;
}
name {
    font-family:  "PT Serif","Georgia","Helvetica Neue",Arial,sans-serif; 
    font-size: 35px;
    font-weight: bold;
}
heading {
    font-family:  'Titillium Web', Verdana, Helvetica, sans-serif;
    font-size: 21px;
    font-weight: bold;
}
#friendly_1 {
position:absolute;
left:190px;
top:370px;
width:80px;
}
#text {
position:absolute;
left:19px;
top:270px;
width:80px;
}
#footer {
   width:960px;
   margin:0 auto;
}
#footer p {
   line-height:50px; /* must be same as the amount of padding applied to the bottom of the body so text will center vertically */
   text-align:left; /* align right, left or center */
}
</style>


  <title>Liyi Zhang </title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <p> &nbsp </p>
  <link href='http://fonts.googleapis.com/css?family=Roboto:300,400,500,700,900,100italic,100,300,300italic,400italic,500italic,900italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="70%" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <p>
          <name>Liyi Zhang</name>
        </p>
        <p>
        <img src="zhang-liyi.jpg" width="30%">
        </p>
        <p>
          <a href="Zhang_Liyi_Resume.pdf">Resume</a> &nbsp/&nbsp
          <a href="https://www.linkedin.com/in/liyi-zhang-1b5041139/"> LinkedIn </a> &nbsp/&nbsp
        <a> Email:</a>  lz2574 at columbia dot edu 
        </p>
        </td>
       </tr>
      </table>
  
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
        <td width="100%" valign="middle">
        <p>
        I am undergraduate in Columbia University, Columbia College, expecting to graduate in Spring 2021. I'm majoring in Statistics and Applied Mathematics. My research interest lies in the general area of probabilistic Machine Learning. My past and current interests include approximate Bayesian inference, model checking and combination in the Bayesian workflow, and probabilistic perspectives on Deep Learning.
        </p>
        <p>
        For a framework of analysis, I usually follow the Box's Loop described in detail in <a href="http://www.cs.columbia.edu/~blei/papers/Blei2014b.pdf">Blei (2014)</a>. The graph below outlines the Box's Loop (comes from the same article).
        </p>
        <p>
        <img src="Images/Bayesian-workflow.png" width="85%">
        </p>
        <p> &nbsp </p>
        </td> 
        </tr>
      </table>
 

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publication</heading>
        </td>
      </tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
    <tr>
      <td width="25%">
        <img src='Images/vcsmc-loglik.png' width="320" height="250">
      </td>
      <td valign="top" width="75%">
        <p>
        <a href="Writings/VCSMC-MLCB.pdf">
            <papertitle>Variational Combinatorial Sequential Monte Carlo in Bayesian Phylogenetic Inference</papertitle>
        </a>
        <br>
          <a href=http://www.cs.columbia.edu/~amoretti/>Antonio K. Moretti</a>,
          <strong>Liyi Zhang</strong>,
          <a href="http://www.cs.columbia.edu/~itsik/">Itsik Pe'er</a>,
        <br>
        <em>Machine Learning in Computational Biology 2020 (MLCB). Oral Presentation. </em>  <br>
        </p>
        <p>Bayesian phylogenetic inference is often conducted via local or sequential search algorithms such as random-walk Markov chain Monte Carlo or Combinatorial Sequential Monte Carlo. These methods sample tree topologies and branch lengths, however when MCMC is used to perform evolutionary parameter learning, convergence often requires long runs with inefficient state space exploration. We introduce Variational Combinatorial Sequential Monte Carlo (VCSMC), a novel Variational Inference method that simultaneously performs both parameter inference and model learning. Our method uses sequential search to construct a variational objective defined on the composite space of phylogenetic trees. We show that VCSMC is computationally efficient and explores higher probability spaces when compared with state-of-the-art Hamiltonian Monte Carlo methods. </p>
      </td>
    </tr>
    </table>



    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Projects</heading>
        </td>
      </tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
    <tr>
      <td width="25%">
        <img src='Images/stack-ternary.png' width="280" height="250">
      </td>
      <td valign="top" width="75%">
        <p>
        <a href="Writings/stack-phylo.pdf">
            <papertitle>Model Stacking in Bayesian Phylogenetic Inference</papertitle>
        </a>
        <br>
        <em>Columbia Statistics - Undergraduate Internship. Work in Progress. </em>  <br>
        </p>
        <p>I'm working with Professor Andrew Gelman to develop MCMC method in R and Stan to enable sampling in discrete spaces in phylogenetic models by isolating discrete models and using stacking of predictive distributions for model combination. Here, I'm still in the process of diagnosing MCMC inference and exploring properties of stacking as a method of model averaging.</p>
      </td>
    </tr>
    </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="25">
    <tr>
      <td width="25%">
        <img src='Images/svrg.png' width="280" height="250">
      </td>
      <td valign="top" width="75%">
        <p>
        <a href="Writings/SVRG_report.pdf">
            <papertitle>Stochastic Variance Reduction for Nonconvex Optimization</papertitle>
        </a>
        <br>
        <em>COMS 4995 Optimization Methods in Machine Learning - Class Group Project </em>  <br>
        </p>
        <p>Stochastic Variance Reduced Gradient (SVRG) is one of the popular method proposed to reduce the variance of gradient in the optimization. In this project, we evaluate its result on nonconvex optimization. We study the method without the convex assumption and try to reproduce previous experiment results to verify their claims. However, we can only partially reproduce their result and the advantage against SGD no longer holds when we use deeper network.</p>
      </td>
    </tr>
    </table>


    <p> &nbsp </p>
    <p> &nbsp </p>  
  </body>
</html>
